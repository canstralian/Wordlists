{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XiYLIQHrmoPWbEa6sMuaudkWMlyjyQBT",
      "authorship_tag": "ABX9TyPdmXDGNq81mpWAvlSCHjnu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/canstralian/Wordlists/blob/main/Password_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORT SECTION"
      ],
      "metadata": {
        "id": "_rBpiFh5E8Na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.31.0"
      ],
      "metadata": {
        "id": "fKDwj-wIIgM2",
        "outputId": "1f12b556-1389-4e76-a053-13c54f55d9d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.31.0 in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64"
      ],
      "metadata": {
        "id": "ZHvSXpPAIh2N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Setting environment variables\n",
        "os.environ['GOOGLE_API_KEY'] = 'your-google-api-key'\n",
        "os.environ['OPENAI_API_KEY'] = 'your-openai-api-key'\n",
        "os.environ['WAND_API_KEY'] = 'your-wand-api-key'\n",
        "os.environ['HF_ACCESS_TOKEN'] = 'your-huggingface-token'\n",
        "os.environ['COHERE_API_KEY'] = 'cohere_api_key'\n",
        "os.environ['GITHUB_TOKEN'] = 'your-github-token'\n",
        "os.environ['GOOGLE_API_KEY_1'] = 'your-google-api-key-1'\n"
      ],
      "metadata": {
        "id": "tB4qDlN5EXoe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing environment variables securely\n",
        "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "wand_api_key = os.getenv('WAND_API_KEY')\n",
        "hf_access_token = os.getenv('HF_ACCESS_TOKEN')\n",
        "cohere_api_key = os.getenv('COHERE_API_KEY')\n",
        "github_token = os.getenv('GITHUB_TOKEN')\n",
        "google_api_key_1 = os.getenv('GOOGLE_API_KEY_1')\n",
        "\n",
        "print(google_api_key)  # Example: Printing the GOOGLE_API_KEY (Avoid printing sensitive keys in practice)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUcg_2U6Ebgz",
        "outputId": "63d24034-6881-4b59-a26d-b6e5415e6cb1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your-google-api-key\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from google.colab import drive\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Your code to access files in Google Drive, for example\n"
      ],
      "metadata": {
        "id": "hoMup1owEiy3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "A9tT4PRpAfxm",
        "outputId": "c730b6e7-0fcf-4afa-a50f-9665e38a057d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/passwords_and_hashes.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import hashlib\n",
        "import random\n",
        "import string\n",
        "import csv\n",
        "\n",
        "# Function to generate strong passwords\n",
        "def generate_password(length=12):\n",
        "    characters = string.ascii_letters + string.digits + string.punctuation\n",
        "    return ''.join(random.choice(characters) for _ in range(length))\n",
        "\n",
        "# Function to hash passwords\n",
        "def hash_password(password):\n",
        "    return hashlib.sha256(password.encode()).hexdigest()\n",
        "\n",
        "# Generate 200 passwords and their hashes\n",
        "passwords = []\n",
        "for _ in range(200):  # 200 passwords\n",
        "    password = generate_password(random.randint(10, 14))  # Random length between 10-14\n",
        "    hashed_password = hash_password(password)\n",
        "    passwords.append([password, hashed_password])\n",
        "\n",
        "# Write to CSV file\n",
        "csv_filename = '/content/passwords_and_hashes.csv'\n",
        "with open(csv_filename, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['password', 'hash'])  # Write header\n",
        "    writer.writerows(passwords)\n",
        "\n",
        "# Output the file path\n",
        "csv_filename"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def generate_passwords_huggingface(model_name, prompt):\n",
        "    \"\"\"\n",
        "    Generates passwords using a Hugging Face model\n",
        "    :param model_name: Hugging Face model name\n",
        "    :param prompt: Prompt to guide password generation\n",
        "    :return: List of generated passwords\n",
        "    \"\"\"\n",
        "    generator = pipeline('text-generation', model=model_name)\n",
        "    generated_passwords = generator(prompt, max_length=10, num_return_sequences=5)\n",
        "\n",
        "    return [entry['generated_text'].strip() for entry in generated_passwords]\n"
      ],
      "metadata": {
        "id": "6Da0AebAGBNy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "def augment_password_dataset(api_key, password_dataset):\n",
        "    \"\"\"\n",
        "    Uses the Wand API for enhancing and tracking password dataset changes.\n",
        "    :param api_key: Wand API key\n",
        "    :param password_dataset: List of passwords to be tracked and enhanced\n",
        "    :return: Updated password dataset\n",
        "    \"\"\"\n",
        "    wandb.login(api_key)  # Log into WandB\n",
        "    wandb.init(project=\"password-dataset-enhancement\")\n",
        "\n",
        "    augmented_data = []\n",
        "\n",
        "    for password in password_dataset:\n",
        "        # Example of transformation or augmentation (just a placeholder for real logic)\n",
        "        augmented_password = password[::-1]  # Reverse the password as an example augmentation\n",
        "        augmented_data.append(augmented_password)\n",
        "\n",
        "    # Log the augmented dataset\n",
        "    wandb.log({\"augmented_passwords\": augmented_data})\n",
        "\n",
        "    return augmented_data\n"
      ],
      "metadata": {
        "id": "kKg1hOxLGE4p"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "def upload_password_dataset_to_gcs(api_key, dataset, bucket_name, file_name):\n",
        "    \"\"\"\n",
        "    Uploads the password dataset to Google Cloud Storage\n",
        "    :param api_key: Google API key\n",
        "    :param dataset: Password dataset to be uploaded\n",
        "    :param bucket_name: Google Cloud Storage bucket name\n",
        "    :param file_name: Name of the file to be saved\n",
        "    \"\"\"\n",
        "    # Initialize Google Cloud Storage client\n",
        "    client = storage.Client.from_service_account_json(api_key)\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "\n",
        "    # Create a blob and upload the dataset\n",
        "    blob = bucket.blob(file_name)\n",
        "    blob.upload_from_string(str(dataset))\n",
        "\n",
        "    print(f\"Password dataset uploaded to gs://{bucket_name}/{file_name}\")\n"
      ],
      "metadata": {
        "id": "YU56cottGIyC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def push_dataset_to_github(api_key, repo_owner, repo_name, file_path, commit_message):\n",
        "    \"\"\"\n",
        "    Pushes the password dataset to a GitHub repository\n",
        "    :param api_key: GitHub API token\n",
        "    :param repo_owner: GitHub repository owner\n",
        "    :param repo_name: GitHub repository name\n",
        "    :param file_path: Path to the file to upload\n",
        "    :param commit_message: Commit message for the push\n",
        "    \"\"\"\n",
        "    url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{file_path}\"\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    # Encode content to Base64\n",
        "    content_base64 = base64.b64encode(content.encode()).decode()\n",
        "\n",
        "    headers = {\n",
        "        'Authorization': f'token {api_key}'\n",
        "    }\n",
        "\n",
        "    data = {\n",
        "        \"message\": commit_message,\n",
        "        \"content\": content_base64,\n",
        "    }\n",
        "\n",
        "    response = requests.put(url, headers=headers, json=data)\n",
        "    if response.status_code == 201:\n",
        "        print(\"Dataset successfully pushed to GitHub!\")\n",
        "    else:\n",
        "        print(f\"Error: {response.json()}\")\n"
      ],
      "metadata": {
        "id": "6RtY97D6GLxo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance_password_dataset(api_keys, dataset):\n",
        "    # 1. Generate password embeddings using Cohere\n",
        "    embeddings = generate_password_embeddings(api_keys['cohere'], dataset)\n",
        "\n",
        "    # 2. Generate creative password suggestions using OpenAI\n",
        "    openai_suggestions = generate_password_suggestions(api_keys['openai'], \"Generate secure password suggestions.\")\n",
        "\n",
        "    # 3. Use Hugging Face to generate text-based passwords\n",
        "    hf_passwords = generate_passwords_huggingface(\"gpt2\", \"Create strong password combinations.\")\n",
        "\n",
        "    # 4. Use Wand to augment dataset\n",
        "    augmented_data = augment_password_dataset(api_keys['wand'], dataset)\n",
        "\n",
        "    # 5. Upload the final dataset to Google Cloud Storage\n",
        "    upload_password_dataset_to_gcs(api_keys['google'], augmented_data, \"your_bucket\", \"augmented_passwords.jsonl\")\n",
        "\n",
        "    # 6. Push to GitHub for version control\n",
        "    push_dataset_to_github(api_keys['github'], \"your_repo_owner\", \"your_repo_name\", \"augmented_passwords.jsonl\", \"Added new augmented passwords.\")\n",
        "\n",
        "    return augmented_data\n"
      ],
      "metadata": {
        "id": "jBX0l2nDGONb"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}